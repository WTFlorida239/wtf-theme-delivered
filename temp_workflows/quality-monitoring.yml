name: Quality Assurance & Monitoring

on:
  schedule:
    # Run daily at 6 AM UTC
    - cron: '0 6 * * *'
  workflow_dispatch:
  push:
    branches: [ main ]

# Avoid overlapping runs on the same ref
concurrency:
  group: quality-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

env:
  SHOPIFY_STORE: wtfswag.myshopify.com
  # Max pages to analyze from sitemap (besides the homepage)
  QUALITY_MAX_URLS: "5"

jobs:
  discover-urls:
    name: Discover URLs to audit
    runs-on: ubuntu-latest
    outputs:
      urls_json: ${{ steps.collect.outputs.urls_json }}
      first_url: ${{ steps.collect.outputs.first_url }}
    steps:
      - name: Discover from sitemap
        id: collect
        run: |
          set -euo pipefail
          sudo apt-get update && sudo apt-get install -y jq curl
          BASE="https://${SHOPIFY_STORE}"
          SITEMAP_URL="$BASE/sitemap.xml"

          # Always include homepage
          urls=("$BASE/")

          echo "Fetching sitemap: $SITEMAP_URL"
          if curl -sSfL "$SITEMAP_URL" -o sitemap.xml ; then
            echo "Parsing sitemap.xml..."
            # Grab first QUALITY_MAX_URLS <loc> entries (excluding checkout/admin endpoints)
            mapfile -t found < <(grep -oP '(?<=<loc>).*?(?=</loc>)' sitemap.xml \
              | grep -E "^https?://" \
              | grep -vE "/(admin|checkout)/" \
              | head -n "${QUALITY_MAX_URLS}")
            urls+=("${found[@]}")
          else
            echo "::warning:: Could not fetch sitemap; auditing homepage only."
          fi

          # De-dup & emit JSON array
          mapfile -t dedup < <(printf "%s\n" "${urls[@]}" | awk '!seen[$0]++')
          urls_json=$(printf '%s\n' "${dedup[@]}" | jq -R . | jq -s .)
          first_url="${dedup[0]}"

          echo "Discovered URLs:"
          echo "$urls_json" | jq -r '.[]'

          echo "urls_json=$urls_json" >> "$GITHUB_OUTPUT"
          echo "first_url=$first_url"   >> "$GITHUB_OUTPUT"

  lighthouse-monitoring:
    name: Lighthouse Performance Monitoring
    runs-on: ubuntu-latest
    needs: [discover-urls]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Lighthouse CI & tools
        run: |
          set -euo pipefail
          npm install -g @lhci/cli lighthouse
          sudo apt-get update && sudo apt-get install -y jq bc

      - name: Write LHCI config (event-aware thresholds)
        env:
          URLS_JSON: ${{ needs.discover-urls.outputs.urls_json }}
        run: |
          set -euo pipefail
          # Be strict on push to main; warn-only on schedule/manual
          if [ "${{ github.event_name }}" = "push" ]; then
            LH_SEVERITY="error"
          else
            LH_SEVERITY="warn"
          fi

          cat > lighthouserc.json <<'JSON'
          {
            "ci": {
              "collect": {
                "url": []
              },
              "assert": {
                "assertions": {
                  "categories:performance": ["__SEVERITY__", {"minScore": 0.85}],
                  "categories:accessibility": ["__SEVERITY__", {"minScore": 0.90}],
                  "categories:best-practices": ["__SEVERITY__", {"minScore": 0.85}],
                  "categories:seo": ["__SEVERITY__", {"minScore": 0.90}]
                }
              },
              "upload": {
                "target": "filesystem",
                "outputDir": "./lighthouse-results"
              }
            }
          }
          JSON

          # Inject URLs & severity
          jq --argjson urls "$URLS_JSON" '.ci.collect.url=$urls' lighthouserc.json > lighthouserc.tmp
          sed "s/__SEVERITY__/${LH_SEVERITY}/g" lighthouserc.tmp > lighthouserc.json
          rm lighthouserc.tmp

          echo "LHCI config:"
          cat lighthouserc.json

      - name: Run Lighthouse audit
        run: |
          set -euo pipefail
          echo "Running Lighthouse performance audit..."
          # Non-blocking on schedule; blocking on push (assertions handle that)
          lhci autorun || echo "â„¹ï¸ Lighthouse audit completed with warnings"

      - name: Process Lighthouse results (averaged)
        run: |
          set -euo pipefail
          echo "Processing Lighthouse results..."

          if [ -f "./lighthouse-results/manifest.json" ]; then
            PERF=$(jq -r '[.[].summary.performance] | add/length * 100 | floor' ./lighthouse-results/manifest.json)
            A11Y=$(jq -r '[.[].summary.accessibility] | add/length * 100 | floor' ./lighthouse-results/manifest.json)
            BP=$(jq -r '[.[].summary["best-practices"]] | add/length * 100 | floor' ./lighthouse-results/manifest.json)
            SEO=$(jq -r '[.[].summary.seo] | add/length * 100 | floor' ./lighthouse-results/manifest.json)

            echo "PERFORMANCE_SCORE=$PERF" >> $GITHUB_ENV
            echo "ACCESSIBILITY_SCORE=$A11Y" >> $GITHUB_ENV
            echo "BEST_PRACTICES_SCORE=$BP" >> $GITHUB_ENV
            echo "SEO_SCORE=$SEO" >> $GITHUB_ENV

            cat > performance-report.md <<EOF
            # WTF Theme Performance Report

            **Date:** $(date)
            **Store:** ${SHOPIFY_STORE}

            ## Lighthouse Average Scores (across collected URLs)
            - **Performance:** ${PERF}/100
            - **Accessibility:** ${A11Y}/100
            - **Best Practices:** ${BP}/100
            - **SEO:** ${SEO}/100

            ## Threshold Checks
            $( [ "$PERF" -lt 85 ] && echo "âš ï¸ Performance score below threshold (85)"; true )
            $( [ "$A11Y" -lt 90 ] && echo "âš ï¸ Accessibility score below threshold (90)"; true )
            $( [ "$BP"   -lt 85 ] && echo "âš ï¸ Best Practices score below threshold (85)"; true )
            $( [ "$SEO"  -lt 90 ] && echo "âš ï¸ SEO score below threshold (90)"; true )
            EOF
          else
            echo "::warning:: No Lighthouse manifest found; skipping summary."
          fi

      - name: Upload Lighthouse results
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-monitoring-results
          path: |
            lighthouse-results/
            lighthouserc.json
            performance-report.md
          retention-days: 30
          if-no-files-found: ignore

  accessibility-audit:
    name: Accessibility Audit (axe)
    runs-on: ubuntu-latest
    needs: [discover-urls]

    steps:
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install axe-core CLI & tools
        run: |
          set -euo pipefail
          npm install -g @axe-core/cli
          sudo apt-get update && sudo apt-get install -y jq

      - name: Run axe against discovered URLs
        env:
          URLS_JSON: ${{ needs.discover-urls.outputs.urls_json }}
        run: |
          set -euo pipefail
          mkdir -p axe-results
          # Iterate URLs and save per-URL reports
          echo "$URLS_JSON" | jq -r '.[]' | while read -r url; do
            safe=$(echo "$url" | sed 's#https\?://##; s#[^A-Za-z0-9._-]#_#g')
            npx axe "$url" --exit 0 --tags wcag2a,wcag2aa,best-practice --save "axe-results/${safe}.json" || true
          done

      - name: Summarize axe results (fail on push if serious/critical)
        run: |
          set -euo pipefail
          SERIOUS=$(jq '[inputs.violations[]? | select(.impact=="serious") ] | length' axe-results/*.json < /dev/null 2>/dev/null || echo 0)
          CRITICAL=$(jq '[inputs.violations[]? | select(.impact=="critical")] | length' axe-results/*.json < /dev/null 2>/dev/null || echo 0)
          TOTAL=$(jq '[inputs.violations[]?] | length' axe-results/*.json < /dev/null 2>/dev/null || echo 0)

          echo "A11Y_SERIOUS=$SERIOUS"   >> $GITHUB_ENV
          echo "A11Y_CRITICAL=$CRITICAL" >> $GITHUB_ENV
          echo "A11Y_TOTAL=$TOTAL"       >> $GITHUB_ENV

          cat > accessibility-report.md <<EOF
          # WTF Theme Accessibility Audit (axe)

          **Date:** $(date)
          **Violations**
          - Critical: ${CRITICAL}
          - Serious:  ${SERIOUS}
          - Total:    ${TOTAL}

          ## Notes
          - Uses axe tags: wcag2a, wcag2aa, best-practice
          - See individual JSON files in artifact for details
          EOF

          if [ "${{ github.event_name }}" = "push" ] && [ "$CRITICAL" -gt 0 -o "$SERIOUS" -gt 5 ]; then
            echo "âŒ Accessibility gate failed (critical>0 or serious>5)"
            exit 1
          fi

      - name: Upload accessibility results
        uses: actions/upload-artifact@v4
        with:
          name: accessibility-audit-results
          path: |
            accessibility-report.md
            axe-results/
          retention-days: 30
          if-no-files-found: ignore

  seo-audit:
    name: SEO Audit (light)
    runs-on: ubuntu-latest
    needs: [discover-urls]

    steps:
      - name: Install tools
        run: |
          set -euo pipefail
          sudo apt-get update && sudo apt-get install -y curl jq

      - name: Check homepage SEO elements
        env:
          HOME_URL: ${{ needs.discover-urls.outputs.first_url }}
        run: |
          set -euo pipefail
          echo "Auditing: $HOME_URL"
          curl -sSL "$HOME_URL" -o home.html || { echo "::warning:: Could not fetch homepage"; touch home.html; }

          HAS_DESC=$(grep -ciE '<meta[^>]+name=["'\'']description["'\'']' home.html || true)
          HAS_OG=$(grep -ciE '<meta[^>]+property=["'\'']og:' home.html || true)
          HAS_CANONICAL=$(grep -ciE '<link[^>]+rel=["'\'']canonical["'\'']' home.html || true)
          HAS_LDJSON=$(grep -ciE 'application/ld\+json' home.html || true)
          TITLE_LEN=$(grep -oP '(?i)(?<=<title>).*?(?=</title>)' home.html | head -n1 | awk '{print length}' || echo 0)

          cat > seo-report.md <<EOF
          # WTF Theme SEO Audit (homepage)

          **Date:** $(date)
          **URL:** ${HOME_URL}

          ## Elements
          - Meta description: $( [ "$HAS_DESC" -gt 0 ] && echo "âœ… Present" || echo "âŒ Missing" )
          - Open Graph tags:  $( [ "$HAS_OG" -gt 0 ] && echo "âœ… Present" || echo "âŒ Missing" )
          - Canonical link:   $( [ "$HAS_CANONICAL" -gt 0 ] && echo "âœ… Present" || echo "âŒ Missing" )
          - JSON-LD:          $( [ "$HAS_LDJSON" -gt 0 ] && echo "âœ… Present" || echo "âŒ Missing" )
          - <title> length:   ${TITLE_LEN} chars (recommended 30â€“60)

          ## Recommendations
          1. Ensure meta description is unique and ~155â€“160 chars
          2. Provide OG tags (title, description, image) for rich sharing
          3. Set canonical URLs on indexable pages
          4. Add JSON-LD (Organization, WebSite, Product as applicable)
          EOF

      - name: Upload SEO results
        uses: actions/upload-artifact@v4
        with:
          name: seo-audit-results
          path: seo-report.md
          retention-days: 30
          if-no-files-found: ignore

  competitor-monitoring:
    name: Competitor Analysis
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: |
          set -euo pipefail
          npm ci
          sudo apt-get update && sudo apt-get install -y jq

      - name: Run competitor audit (if script exists)
        run: |
          set -euo pipefail
          if npm run | grep -q "competitors:audit"; then
            npm run competitors:audit
          else
            echo "â­ï¸ No competitors:audit script found; skipping."
          fi

      - name: Generate competitor insights
        run: |
          set -euo pipefail
          OUT="competitive-analysis.md"
          if [ -f "docs/competitor-insights.json" ]; then
            TOP=$(jq -r '.competitors?[0:5][]? | "- " + (.name // "Unknown") + " â€” " + (.city // .location // "N/A") + " | Strengths: " + ((.strengths // [])|join(", "))' docs/competitor-insights.json || true)
          fi

          cat > "$OUT" <<EOF
          # WTF Competitive Analysis Report

          **Date:** $(date)

          ## Snapshot (top competitors)
          ${TOP:-"- Data not available; run competitors:audit to populate docs/competitor-insights.json."}

          ## Recommended Actions
          1. Monitor competitor pricing and promotions
          2. Track new menu items and seasonal offerings
          3. Analyze competitor social media engagement
          4. Review customer feedback on competitor locations
          5. Update WTF positioning based on market changes
          EOF

      - name: Upload competitor analysis
        uses: actions/upload-artifact@v4
        with:
          name: competitor-analysis
          path: competitive-analysis.md
          retention-days: 30
          if-no-files-found: ignore

  quality-summary:
    name: Quality Summary Report
    runs-on: ubuntu-latest
    needs:
      - lighthouse-monitoring
      - accessibility-audit
      - seo-audit
      - competitor-monitoring
    if: always()

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4

      - name: Create quality summary
        run: |
          set -euo pipefail
          cat > quality-summary.md <<EOF
          # WTF Theme Quality Summary

          **Date:** $(date)
          **Run:** ${{ github.run_number }}

          ## Job Status
          - Lighthouse:  ${{ needs.lighthouse-monitoring.result }}
          - Accessibility: ${{ needs.accessibility-audit.result }}
          - SEO: ${{ needs.seo-audit.result }}
          - Competitors: ${{ needs.competitor-monitoring.result }}

          ## Overall
          $( if [ "${{ needs.lighthouse-monitoring.result }}" = "success" ] && [ "${{ needs.accessibility-audit.result }}" = "success" ] && [ "${{ needs.seo-audit.result }}" = "success" ]; then
               echo "ðŸŸ¢ All quality checks passed";
             else
               echo "ðŸŸ¡ Some quality checks need attention";
             fi)

          ## Next Actions
          1. Review Lighthouse performance-report.md
          2. Review accessibility-report.md and axe JSONs
          3. Review seo-report.md for homepage issues
          4. Review competitive-analysis.md for market movement
          EOF

      - name: Upload quality summary
        uses: actions/upload-artifact@v4
        with:
          name: quality-summary-report
          path: quality-summary.md
          retention-days: 90
          if-no-files-found: ignore
